import sys
import csv
import os
import glob
import pandas as pd
import numpy as np
from math import pi
from datetime import datetime as dt
from bokeh.io import output_file,show
from bokeh.models import DatetimeTickFormatter,ColumnDataSource
from bokeh.models import HoverTool
import bokeh.plotting as plot
from bokeh.transform import jitter
from bokeh.layouts import column,gridplot

def extract_and_seperate(path,outIdiomatic,outNonidiomatic):

    # 'arg[] path' is the path that contains Siamese's CSV output
    # 'arg[] outIdiomatic' is the outputted idiomatic.csv
    # 'arg[] outNonidiomatic' is the outputted nonidiomatic
    
    pattern_tokens=[]
    siameseCSVsFiles = []  # List of the CSVs generated by Siamese

    # idiomName:marker Dictionary
    marker_dict = {
        'dict-comprehension':'circle',
        'enumerate':'triangle',
        'file-reading-statement':'square',
        'list-comprehension':'diamond',
        'if-statement':'hex',
        'string-formatting':'asterisk',
        'code-formatting':'CircleCross',
        'set':'cross',
        'tuple':'InvertedTriangle',
        'variable-swapping':'SquareCross'
    }

    # Get all the CSV file names in the specified path
    # r=root, d=directories, f = files
    for r, d, f in os.walk(path):
        for file in f:
            if '.csv' in file:
                siameseCSVsFiles.append(os.path.join(r, file))
    
    # Creating the header row for outIdiomatic and outNonidiomatic
    with open(outIdiomatic, 'w', newline='') as idiomaticCSV:
        print("CommitNO,CommitID,fileName,methodName,startLine,endLine,style,idiomName,color,marker",file=idiomaticCSV)
    with open(outNonidiomatic, 'w', newline='') as nonidiomaticCSV:
        print("CommitNO,CommitID,fileName,methodName,startLine,endLine,style,idiomName,color,marker,recommend",file=nonidiomaticCSV)
    
    for f in siameseCSVsFiles:

        # Extracting repoName, commitNo, and commitID from Siamese's CSV file names
        # i.e.: horovod_447_1gtfvx.csv
        #  > file_name_splitted[0]: 'horovod'
        #  > file_name_splitted[1]: '447'
        #  > file_name_spllited[2]: '1gtfvx'
        file_name_splitted = os.path.basename(f).replace(".csv","").split("_")
        (repoName,commitNO,commitID) = file_name_splitted

        # Reading rows from a CSV
        with open(f, "r") as w:
            # data = list(csv.reader(w))
            data = w.read()
            data_splitted = data.split("@")    # Used the '@' symbol to split between each record in the CSV
            data_splitted.pop()                # An extra element is tailed at the end because of the last '@' in the last row    
         
        # Loop through each row in a CSV object 'f'
        for row in data_splitted:
            
            processed_row = []
            idiom_name_tokens = []
            
            row_splitted = row.split(',/')      # Split between the query columm and the pattern column
            path_query = row_splitted[0]        # The query part of the row
            path_pattern = row_splitted[1]      # The pattern part of the row

            # Extract the pattern type (pi/npi) and style from path_pattern
            path_pattern_tokens = path_pattern.split('.py')[0].split('/')         
            # Extract the type (first element in path_pattern_tokens)

            # ['pi','if','statement'] 
            pattern_tokens = path_pattern_tokens[len(path_pattern_tokens)-1].split('-') 
            pi_or_npi = pattern_tokens[0]
            
            # Extract the style (the remaining elements in path_pattern_tokens)
            for i in range(1,len(pattern_tokens)):
                idiom_name_tokens.append(pattern_tokens[i])
            idiom_name = '-'.join(idiom_name_tokens)
        
            # Extract the query's fileName, methodName, startLine and endLine
            path_query_tokens = path_query.split('/')
            query_file_name = path_query_tokens[len(path_query_tokens)-1].split('.py')[0]+'.py'
            query_method_name = path_query_tokens[len(path_query_tokens)-1].split('.py_')[1].split('#')[0]
            query_method_startLine = path_query_tokens[len(path_query_tokens)-1].split('.py_')[1].split('#')[1]
            query_method_endLine = path_query_tokens[len(path_query_tokens)-1].split('.py_')[1].split('#')[2]

            
            # "CommitNO,CommitID,fileName,methodName,startLine,endLine,style,idiomName"
            processed_row.append(commitNO)
            processed_row.append(commitID)
            processed_row.append(query_file_name)
            processed_row.append(query_method_name)
            processed_row.append(query_method_startLine)
            processed_row.append(query_method_endLine)
            processed_row.append(pi_or_npi)
            processed_row.append(idiom_name)

            # Label the color (red/green) to be used for the markers
            # 'green' for pi, 'red' for npi
            if processed_row[6] == 'pi':
                processed_row.append('green')
            else:
                processed_row.append('red')
                
            # Add the marker based on the idiomName (processed_row[7]) to processed_row[]
            processed_row.append(marker_dict.get(processed_row[7]))

            # Final check if the row is of a PI or NPI
            # if it's a PI, append the processed_row to outIdiomatic.csv
            # if it's a NPI, add recommendPattern first then append to outNonidiomatic.csv
            if processed_row[6] == 'pi':
                with open(outIdiomatic,'a',newline='') as outIdiomaticCSV:
                    print(processed_row,file=outIdiomaticCSV)
            else:
                # Extract the recommendation pattern
                recommend_pattern = path_pattern.split('#')
                # Encode tabes and newline as alphabetical '\t' and '\n' and remove the tailing '@' inherited from the Siamese's output
                recommend_pattern = recommend_pattern[len(recommend_pattern)-1].replace('\n','\\n').replace('\t','\\t').replace('@','')
                # Append recommend_pattern to process_row
                processed_row.append(recommend_pattern)

                # Append the completed processed_row to outNonidiomatic
                with open(outNonidiomatic,'a',newline='') as outNonidiomaticCSV:
                    print(processed_row,file=outNonidiomaticCSV)
            

siamese_input = str(sys.argv[1])
out_idiomatic_csv = str(sys.argv[2])
out_nonidiomatic_csv = str(sys.argv[3])

extract_and_seperate(siamese_input,out_idiomatic_csv,out_nonidiomatic_csv)
# plot()








            
            
            


